{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Data Preparation:\n",
    "\n",
    "Prepare a Support Ticket dataset (Ticket ID, User Query, Category).\n",
    "\n",
    "Normalize text (remove special characters, lowercase)."
   ],
   "id": "541ccdac33492b7c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T14:17:07.330471Z",
     "start_time": "2024-12-18T14:17:07.314914Z"
    }
   },
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "device = torch.device('cpu')\n",
    "data_path = r\"C:\\Users\\Manian VJS\\Downloads\\support_ticket_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "def normalize_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "df['User Query'] = df['User Query'].apply(normalize_text)\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(df['Category'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['User Query'], labels, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a240b13146ef59f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2.Multi-Label Classification:\n",
    "\n",
    "Train a BERT model for multi-label classification of support tickets.\n",
    "\n",
    "Fine-tune the BERT model to classify tickets into multiple tags."
   ],
   "id": "f8bfb36fdb1212b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:17:17.295394Z",
     "start_time": "2024-12-18T14:17:16.934218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TicketDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': label\n",
    "        }\n",
    "MAX_LEN = 256\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset = TicketDataset(X_train.to_list(), y_train, tokenizer, MAX_LEN)\n",
    "test_dataset = TicketDataset(X_test.to_list(), y_test, tokenizer, MAX_LEN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ],
   "id": "3ce9b813c360c938",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example",
   "id": "bf028dd3bb620bcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:10:49.731111Z",
     "start_time": "2024-12-18T15:10:48.816419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_batch = next(iter(train_loader))\n",
    "example_input_ids = example_batch['input_ids'].to(device)\n",
    "example_attention_mask = example_batch['attention_mask'].to(device)\n",
    "example_labels = example_batch['labels'].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    example_outputs = model(example_input_ids, attention_mask=example_attention_mask)\n",
    "    example_logits = example_outputs.logits\n",
    "    example_preds = torch.sigmoid(example_logits).cpu().numpy()\n",
    "print(\"Example predictions: \", example_preds)\n",
    "print(\"Example true labels: \", example_labels.cpu().numpy())"
   ],
   "id": "e43892ea706af0cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example predictions:  [[0.42263746 0.5583495  0.37065837 0.47111332 0.37068075 0.5853716\n",
      "  0.5816554  0.55073833 0.59850115 0.41836867 0.50048196 0.47200292\n",
      "  0.56716317 0.45134288 0.522708   0.4105469  0.56048894 0.4069184\n",
      "  0.5966374  0.33741415 0.51642346 0.5047139  0.40780765 0.5089507 ]\n",
      " [0.34196344 0.6061839  0.29007187 0.47739378 0.45914516 0.6233553\n",
      "  0.61203873 0.56748176 0.553133   0.4419453  0.5616265  0.49003357\n",
      "  0.53530115 0.42320022 0.51467514 0.43902892 0.48194712 0.380439\n",
      "  0.61810523 0.3538714  0.46859878 0.46764454 0.43681076 0.55148077]\n",
      " [0.44385645 0.5724901  0.36882788 0.47315145 0.42359942 0.52633953\n",
      "  0.6265597  0.5468251  0.60155976 0.4445151  0.45513654 0.47009614\n",
      "  0.55933267 0.5509839  0.4803009  0.4394452  0.56790274 0.42013136\n",
      "  0.49835286 0.39231923 0.45044455 0.5463756  0.43492782 0.5019215 ]\n",
      " [0.42089    0.58522326 0.34094793 0.4642755  0.40175596 0.51967734\n",
      "  0.52808446 0.52476054 0.63571864 0.4242338  0.51904255 0.44998792\n",
      "  0.5946599  0.45640555 0.4834938  0.41893438 0.5625184  0.39587468\n",
      "  0.63527656 0.36167753 0.5635673  0.5115252  0.47053787 0.49597397]\n",
      " [0.4656648  0.53801954 0.39760467 0.4548847  0.36519378 0.5002908\n",
      "  0.5695158  0.58006585 0.6110169  0.4316778  0.45510587 0.4736185\n",
      "  0.5862019  0.52933455 0.5363951  0.4219769  0.5274496  0.42435566\n",
      "  0.54802704 0.34556878 0.47567832 0.5309148  0.38565433 0.49977455]\n",
      " [0.4348866  0.5273177  0.35805887 0.4379364  0.39395812 0.5018317\n",
      "  0.5637423  0.55314136 0.6309936  0.4907591  0.47990477 0.48984858\n",
      "  0.5715571  0.4891115  0.48366353 0.48206756 0.5453276  0.35808927\n",
      "  0.515819   0.34212923 0.5210431  0.54819655 0.38592368 0.5625112 ]\n",
      " [0.42040178 0.53217304 0.38177696 0.46686277 0.43150038 0.50320494\n",
      "  0.57075906 0.53920794 0.5992657  0.47051343 0.4213404  0.5125979\n",
      "  0.5798193  0.4954777  0.5539614  0.42725506 0.60136306 0.38622996\n",
      "  0.54711455 0.33632383 0.5587656  0.53504103 0.39350432 0.4930095 ]\n",
      " [0.41118664 0.5938309  0.3235836  0.4481777  0.35697606 0.56431067\n",
      "  0.6080386  0.55158716 0.573676   0.46753675 0.5506276  0.5656184\n",
      "  0.59290665 0.40813842 0.477875   0.38261524 0.60365564 0.4440007\n",
      "  0.60472876 0.38955    0.5149066  0.48304868 0.47199145 0.5762728 ]]\n",
      "Example true labels:  [[1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.]]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "4.API Development:\n",
    "\n",
    "Develop an API endpoint /auto-tag-ticket.\n",
    "\n",
    "Return a list of relevant tags for each support ticket."
   ],
   "id": "99ab1cb623d3f55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:14:54.988564Z",
     "start_time": "2024-12-18T15:14:54.972940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_ticket_info(ticket_id):\n",
    "    ticket_row = df.loc[df['Ticket ID'] == ticket_id]\n",
    "    if ticket_row.empty:\n",
    "        return \"Ticket ID not found.\"\n",
    "    user_query = ticket_row['User Query'].values[0]\n",
    "    actual_category = ticket_row['Category'].values[0]\n",
    "    predicted_category = get_prediction(user_query)\n",
    "    return user_query, actual_category, predicted_category\n",
    "def get_prediction(ticket_query):\n",
    "    model.eval()\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        ticket_query,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    tags = mlb.inverse_transform(probs > 0.5)\n",
    "    return tags"
   ],
   "id": "e9b3e6e879a568d4",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:15:12.268329Z",
     "start_time": "2024-12-18T15:15:05.029855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ticket_id = input(\"Give the ID: \")\n",
    "user_query, actual_category, predicted_category = get_ticket_info(ticket_id)\n",
    "print(f\"User Query: {user_query}\")\n",
    "print(f\"Actual Category: {actual_category}\")\n",
    "print(f\"Predicted Category: {predicted_category}\")"
   ],
   "id": "9c319570d40df6c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: payment issue occurred\n",
      "Actual Category: Delivery Issue\n",
      "Predicted Category: [('D', 'Q', 'S', 'a', 'c', 'e', 'i', 'l', 'n', 'p', 'r', 't', 'y')]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5.Testing:\n",
    "\n",
    "Test the API with support ticket samples in Postman."
   ],
   "id": "a3c8841401bb7151"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:18:06.420828Z",
     "start_time": "2024-12-18T15:18:06.404773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "class Ticket(BaseModel):\n",
    "    user_query: str"
   ],
   "id": "6acd81ea714045b0",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-18T15:22:13.099571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fastapi import FastAPI,\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "from typing import List\n",
    "import uvicorn\n",
    "app = FastAPI()\n",
    "class Ticket(BaseModel):\n",
    "    user_query: str\n",
    "class Feedback(BaseModel):\n",
    "    ticket_id: str\n",
    "    user_query: str\n",
    "    correct_tags: List[str]\n",
    "feedback_data = []\n",
    "@app.post(\"/auto-tag-ticket\")\n",
    "async def auto_tag_ticket(ticket: Ticket):\n",
    "    ticket_query = ticket.user_query\n",
    "    predicted_tags = get_prediction(ticket_query)\n",
    "    return {\"tags\": predicted_tags}\n",
    "@app.post(\"/feedback\")\n",
    "async def collect_feedback(feedback: Feedback):\n",
    "    feedback_entry = feedback.dict()\n",
    "    feedback_data.append(feedback_entry)\n",
    "    with open('feedback.json', 'w') as f:\n",
    "        json.dump(feedback_data, f)\n",
    "    return {\"message\": \"Feedback received. Thank you!\"}\n",
    "def get_prediction(ticket_query):\n",
    "    model.eval()\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        ticket_query,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    tags = mlb.inverse_transform(probs > 0.5)\n",
    "    return tags\n",
    "config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000)\n",
    "server = uvicorn.Server(config)\n",
    "await server.serve()"
   ],
   "id": "9351b5660e302dff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [2888]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a1fca78836eb0a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
